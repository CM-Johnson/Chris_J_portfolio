{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing machine learning models on a regression task\n",
    "This programming example is from an assignment from the coursera course and “Applied Machine Learning in Python”. The purpose of including this is that I hope it demonstrates that I'm building an understanding of how to use machine learning tools and get a grasp on some of the considerations needed to handle data and develop models.<br>\n",
    "I provide a summary of the assignment here and the full text of the assignment at the end of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This assignment is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time. (i.e. predict the 'compliance' field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and validation data, split into target and useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', encoding = 'ISO-8859-1', low_memory=False).set_index(['ticket_id'])\n",
    "validate = pd.read_csv('test.csv', encoding = 'ISO-8859-1', low_memory=False).set_index(['ticket_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target that I'm trying to predict is 'compliance'. This is provided only in the training data, not the validation data.<br>\n",
    "I'll separate the target out after processing. I'll add a fake compliance value to the validation data for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate['compliance'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation data has fewer features than the training data (presumably to prevent using fields that would create data leakage). I'm going to reduce the data to set of features that the two data sets have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = data.columns\n",
    "val_features = validate.columns\n",
    "feature_intersection = list(set(train_features) & set(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[feature_intersection]\n",
    "validate = validate[feature_intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['violation_code',\n",
       " 'violation_street_number',\n",
       " 'violation_zip_code',\n",
       " 'state',\n",
       " 'state_fee',\n",
       " 'non_us_str_code',\n",
       " 'fine_amount',\n",
       " 'mailing_address_str_number',\n",
       " 'grafitti_status',\n",
       " 'admin_fee',\n",
       " 'discount_amount',\n",
       " 'mailing_address_str_name',\n",
       " 'hearing_date',\n",
       " 'clean_up_cost',\n",
       " 'zip_code',\n",
       " 'city',\n",
       " 'agency_name',\n",
       " 'violator_name',\n",
       " 'violation_description',\n",
       " 'country',\n",
       " 'late_fee',\n",
       " 'disposition',\n",
       " 'judgment_amount',\n",
       " 'compliance',\n",
       " 'inspector_name',\n",
       " 'ticket_issued_date',\n",
       " 'violation_street_name']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_zip_code</th>\n",
       "      <th>state</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>non_us_str_code</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>grafitti_status</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>...</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>country</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>disposition</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>compliance</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>ticket_issued_date</th>\n",
       "      <th>violation_street_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22056</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>INVESTMENT INC., MIDWEST MORTGAGE</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "      <td>USA</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Responsible by Default</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>2004-03-16 11:40:00</td>\n",
       "      <td>TYLER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27586</th>\n",
       "      <td>61-63.0600</td>\n",
       "      <td>4311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Michigan, Covenant House</td>\n",
       "      <td>Failed To Secure Permit For Lawful Use Of Buil...</td>\n",
       "      <td>USA</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Responsible by Determination</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Williams, Darrin</td>\n",
       "      <td>2004-04-23 12:30:00</td>\n",
       "      <td>CENTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22062</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>23658.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SANDERS, DERRON</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not responsible by Dismissal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>2004-04-26 13:40:00</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22084</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MOROSI, MIKE</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not responsible by City Dismissal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>2004-04-26 13:30:00</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22093</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NATHANIEL, NEAL</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not responsible by Dismissal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>2004-04-26 13:00:00</td>\n",
       "      <td>CHURCHILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          violation_code  violation_street_number  violation_zip_code state  \\\n",
       "ticket_id                                                                     \n",
       "22056          9-1-36(a)                   2900.0                 NaN    IL   \n",
       "27586         61-63.0600                   4311.0                 NaN    MI   \n",
       "22062          9-1-36(a)                   1449.0                 NaN    MI   \n",
       "22084          9-1-36(a)                   1441.0                 NaN    MI   \n",
       "22093          9-1-36(a)                   2449.0                 NaN    MI   \n",
       "\n",
       "           state_fee non_us_str_code  fine_amount  mailing_address_str_number  \\\n",
       "ticket_id                                                                       \n",
       "22056           10.0             NaN        250.0                         3.0   \n",
       "27586           10.0             NaN        750.0                      2959.0   \n",
       "22062            0.0             NaN        250.0                     23658.0   \n",
       "22084            0.0             NaN        250.0                         5.0   \n",
       "22093            0.0             NaN        250.0                      7449.0   \n",
       "\n",
       "          grafitti_status  admin_fee          ...           \\\n",
       "ticket_id                                     ...            \n",
       "22056                 NaN       20.0          ...            \n",
       "27586                 NaN       20.0          ...            \n",
       "22062                 NaN        0.0          ...            \n",
       "22084                 NaN        0.0          ...            \n",
       "22093                 NaN        0.0          ...            \n",
       "\n",
       "                               violator_name  \\\n",
       "ticket_id                                      \n",
       "22056      INVESTMENT INC., MIDWEST MORTGAGE   \n",
       "27586               Michigan, Covenant House   \n",
       "22062                        SANDERS, DERRON   \n",
       "22084                           MOROSI, MIKE   \n",
       "22093                        NATHANIEL, NEAL   \n",
       "\n",
       "                                       violation_description country  \\\n",
       "ticket_id                                                              \n",
       "22056      Failure of owner to obtain certificate of comp...     USA   \n",
       "27586      Failed To Secure Permit For Lawful Use Of Buil...     USA   \n",
       "22062      Failure of owner to obtain certificate of comp...     USA   \n",
       "22084      Failure of owner to obtain certificate of comp...     USA   \n",
       "22093      Failure of owner to obtain certificate of comp...     USA   \n",
       "\n",
       "           late_fee                        disposition judgment_amount  \\\n",
       "ticket_id                                                                \n",
       "22056          25.0             Responsible by Default           305.0   \n",
       "27586          75.0       Responsible by Determination           855.0   \n",
       "22062           0.0       Not responsible by Dismissal             0.0   \n",
       "22084           0.0  Not responsible by City Dismissal             0.0   \n",
       "22093           0.0       Not responsible by Dismissal             0.0   \n",
       "\n",
       "          compliance    inspector_name   ticket_issued_date  \\\n",
       "ticket_id                                                     \n",
       "22056            0.0   Sims, Martinzie  2004-03-16 11:40:00   \n",
       "27586            1.0  Williams, Darrin  2004-04-23 12:30:00   \n",
       "22062            NaN   Sims, Martinzie  2004-04-26 13:40:00   \n",
       "22084            NaN   Sims, Martinzie  2004-04-26 13:30:00   \n",
       "22093            NaN   Sims, Martinzie  2004-04-26 13:00:00   \n",
       "\n",
       "          violation_street_name  \n",
       "ticket_id                        \n",
       "22056                     TYLER  \n",
       "27586                   CENTRAL  \n",
       "22062                LONGFELLOW  \n",
       "22084                LONGFELLOW  \n",
       "22093                 CHURCHILL  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data looks like discrete data, some continuous and numerical, some continuous and date-time.<br>\n",
    "sklearn features have to be numerical, so I'll have to transform a bunch of these features.<br>\n",
    "I'll aim for decision trees since they can handle different data input types. Once consequence is that making sure the continuous data is scaled is not a big deal.<br><br>\n",
    "## Feature extraction. What to do with the various categorical data categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the street addresses, I have some tables that allow transforming the ticket ID into latitude and longitude coordinates, making that continuous in a meaningful way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = pd.read_csv('addresses.csv')\n",
    "latlon = pd.read_csv('latlons.csv')\n",
    "location = pd.merge(address,latlon, on = 'address', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77242</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77243</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103945</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138219</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                 address        lat        lon\n",
       "0      22056  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "1      77242  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "2      77243  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "3     103945  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "4     138219  2900 tyler, Detroit MI  42.390729 -83.124268"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = pd.merge(data,location, left_index = True, right_on = 'ticket_id', how = 'left')\n",
    "validate_loc = pd.merge(validate,location, left_index = True, right_on = 'ticket_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful address questions:\n",
    "1. Is the violation address the same as the mailing address (does the owner live there)\n",
    "2. Are they even in the same state? -I'll split out the mailing address states below\n",
    "3. Are they in the same country?  -turns out not to have utility in the validation set - see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll use street number as a proxy for the entire address to compare violation and mailing addresses\n",
    "for df in [data_loc, validate_loc]:\n",
    "    df['same_address'] = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['violation_street_number'] == row['mailing_address_str_number']: df.loc[idx,'same_address'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other categorical data, how useful are categories in the training data for thinking about validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training data</th>\n",
       "      <th>validation data</th>\n",
       "      <th>both datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violation_code</th>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violator_name</th>\n",
       "      <td>119993</td>\n",
       "      <td>38516</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_us_str_code</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency_name</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disposition</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 training data  validation data  both datasets\n",
       "country                      5                1              1\n",
       "violation_code             235              151            131\n",
       "violator_name           119993            38516           4316\n",
       "non_us_str_code              3                1              0\n",
       "agency_name                  5                3              3\n",
       "disposition                  9                8              4\n",
       "state                       60               59             59"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['training data','validation data','both datasets']\n",
    "first = 0\n",
    "for category in ['country','violation_code','violator_name','non_us_str_code','agency_name','disposition', 'state']:\n",
    "    train_cat = data_loc[category].unique()\n",
    "    val_cat = validate_loc[category].unique()\n",
    "    both_cat = list(set(train_cat) & set(val_cat))\n",
    "    if first != 0:\n",
    "        temp_df = pd.DataFrame([[len(train_cat),len(val_cat),len(both_cat)]], index = [category], columns = cols)\n",
    "        category_df = pd.concat([category_df,temp_df])\n",
    "    else:\n",
    "        category_df = pd.DataFrame([[len(train_cat),len(val_cat),len(both_cat)]], index = [category], columns = cols)\n",
    "        first += 1\n",
    "category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**country** no information in the validation data set<br>\n",
    "**violation_code** most of the intersection is in the validation data. Use this after some cleaning<br>\n",
    "**violator_name** not much overlap here. Discard this<br>\n",
    "**non_us_str_code** no information in the validation data set and no overlap with the training data<br>\n",
    "**agency_name** all of the intersection is in the validation data. Use this after some cleaning<br>\n",
    "**disposition** half of the intersection is in the validation data. Use this after some cleaning<br>\n",
    "**state** all of the intersection is in the validation data. Use this after some cleaning<br>\n",
    "\n",
    "### I'll use one hot encoding to capture the categorical data & only keep things that are in the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['violation_code','agency_name','disposition','state']\n",
    "train_dummies = pd.get_dummies(data_loc[cols])\n",
    "val_dummies = pd.get_dummies(validate_loc[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummy_features = train_dummies.columns\n",
    "val_dummy_features = val_dummies.columns\n",
    "dummy_feature_intersection = list(set(train_dummy_features) & set(val_dummy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = train_dummies[dummy_feature_intersection]\n",
    "val_dummies = val_dummies[dummy_feature_intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 196\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dummies.columns),len(val_dummies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date-time information\n",
    "### Use ticket date and hearing date information. Also get the delta between these in case that's informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date-time format, get the delta, convert all to numeric format\n",
    "for df in [data_loc, validate_loc]:\n",
    "    df['ticket_issued_date'] = pd.to_datetime(df['ticket_issued_date'])\n",
    "    df['hearing_date'] = pd.to_datetime(df['hearing_date'])\n",
    "    df['lag'] = df['hearing_date'] - df['ticket_issued_date']\n",
    "    df['ticket_issued_date'] = pd.to_numeric(df['ticket_issued_date'])\n",
    "    df['hearing_date'] = pd.to_numeric(df['hearing_date'])\n",
    "    df['lag'] = pd.to_numeric(df['lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat the features data to contain those that we wish to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fine_amount','late_fee','discount_amount','clean_up_cost',\n",
    "        'judgment_amount','lat','lon','ticket_issued_date','hearing_date','compliance']\n",
    "\n",
    "new_train = data_loc[['same_address','lag']]\n",
    "continuous_train = data_loc[cols]\n",
    "processed_train = pd.merge(train_dummies, new_train, left_index = True, right_index = True)\n",
    "processed_train = pd.merge(processed_train, continuous_train, left_index = True, right_index = True)\n",
    "processed_train.fillna(0,inplace = True) \n",
    "\n",
    "new_val = validate_loc[['same_address','lag']]\n",
    "continuous_val = validate_loc[cols]\n",
    "processed_val = pd.merge(val_dummies, new_val, left_index = True, right_index = True)\n",
    "processed_val = pd.merge(processed_val, continuous_val, left_index = True, right_index = True)\n",
    "processed_val.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250306, 208)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Now to look at how some ML models perform\n",
    "I'll use decision trees since they're supposed to handle different data types well.<br>\n",
    "The assignment called for predicting the probability of the target, not the category, so I'll use regressor forms of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = processed_train.drop(columns = ['compliance'])\n",
    "y_data = processed_train['compliance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor AUC: 0.8693610448550965\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Regressor AUC:',roc_auc_score(y_test, rfr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor AUC: 0.8900906924867573\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting Regressor AUC:',roc_auc_score(y_test, gbr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off the shelf, the gradient boosting regressor outperforms the random forest regressor at this task\n",
    "Only by a little. Is that a function of chance of the train-test split? I'll do some cross-validation for a closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR cross-validation (AUC) [0.86264019 0.90095469 0.88792614 0.85911205 0.87127858]\n"
     ]
    }
   ],
   "source": [
    "print ('GBR cross-validation (AUC)', cross_val_score(gbr, X_data, y_data, cv=5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR cross-validation (AUC) [0.75971513 0.88335973 0.86168623 0.81969624 0.84214297]\n"
     ]
    }
   ],
   "source": [
    "print ('RFR cross-validation (AUC)', cross_val_score(rfr, X_data, y_data, cv=5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation supports GBR being the better model\n",
    "Execute a grid search to optimize some of the key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vals = {'learning_rate':[0.05, 0.1, 0.2],'n_estimators':[50,100,200]}\n",
    "\n",
    "grid_search_GBR = GridSearchCV(gbr, param_grid = test_vals, scoring = 'roc_auc').fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. AUC):  {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Grid best score (AUC):  0.8775710851666731\n"
     ]
    }
   ],
   "source": [
    "print('Grid best parameter (max. AUC): ', grid_search_GBR.best_params_)\n",
    "print('Grid best score (AUC): ', grid_search_GBR.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got some optimal parameters from the input, the learning_rate is the same as the default value, but n_estimators is larger. This didn't result in any dramatic increase in AUC, however. Deploy these values in creating the model.\n",
    "\n",
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor(learning_rate = 0.1, n_estimators = 200, random_state=0).fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = processed_val.drop(columns = ['compliance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "271384    0.107289\n",
       "271385    0.022958\n",
       "271386    0.067080\n",
       "271387    0.058728\n",
       "18620     0.264914\n",
       "Name: compliance, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = GBR.predict(X_val)\n",
    "predictions = pd.Series(y_predict, index = X_val.index)\n",
    "predictions.name = 'compliance'\n",
    "predictions.index.name = 'ticket_id'\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately, I can't show you how the model performed on the validation data. \n",
    "The predictions are how likely the model thinks that a predicted ticket_id will be paid (compliance) The 'compliance' field is used to grade the assignment and not available to the students. I do remember that the AUC on the validation data was a couple points below what I saw on the test data from the train/test splits. This suggests that the model may have been over fit to the training data and/or that there was some data leakage in the set that I did not discover. Under other circumstances I would do some more data exploration and refine the model to discover the source of leakage and avoid over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Description of the assignment\n",
    "## Assignment 4 - Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This assignment is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "All data for this assignment has been provided to us through the [Detroit Open Data Portal](https://data.detroitmi.gov/). **Only the data already included in your Coursera directory can be used for training the model for this assignment.** Nonetheless, we encourage you to look into data from other Detroit datasets to help inform feature creation and model selection. We recommend taking a look at the following related datasets:\n",
    "\n",
    "* [Building Permits](https://data.detroitmi.gov/Property-Parcels/Building-Permits/xw2a-a7tf)\n",
    "* [Trades Permits](https://data.detroitmi.gov/Property-Parcels/Trades-Permits/635b-dsgv)\n",
    "* [Improve Detroit: Submitted Issues](https://data.detroitmi.gov/Government/Improve-Detroit-Submitted-Issues/fwz3-w3yn)\n",
    "* [DPD: Citizen Complaints](https://data.detroitmi.gov/Public-Safety/DPD-Citizen-Complaints-2016/kahe-efs3)\n",
    "* [Parcel Map](https://data.detroitmi.gov/Property-Parcels/Parcel-Map/fxkw-udwf)\n",
    "\n",
    "___\n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is compliance, which is True if the ticket was paid early, on time, or within one month of the hearing data, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible. Compliance, as well as a handful of other variables that will not be available at test-time, are only included in train.csv.\n",
    "\n",
    "Note: All tickets where the violators were found not responsible are not considered during evaluation. They are included in the training set as an additional source of data for visualization, and to enable unsupervised and semi-supervised approaches. However, they are not included in the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    test.csv - the test set (all tickets issued 2012-2016)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUROC of 0.7 passes this assignment, over 0.75 will recieve full points.\n",
    "___\n",
    "\n",
    "For this assignment, create a function that trains a model to predict blight ticket compliance in Detroit using `train.csv`. Using this model, return a series of length 61001 with the data being the probability that each corresponding ticket from `test.csv` will be paid, and the index being the ticket_id.\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
